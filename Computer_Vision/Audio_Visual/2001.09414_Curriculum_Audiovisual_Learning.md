# Curriculum Audiovisual Learning, Hu et. al.

Paper: https://arxiv.org/pdf/2001.09414.pdf  

## Methodogy Summary
1) Use video annotations to figure out the number of sound sources in the video. For example, if a video has a dog barking and a cat meowing, it will contain 2 annotations.  
2) Train a network to "count" or regress the number of sound sources in the video, given the audio clip. They capture the sound source as a Poisson distribution (discrete) over the possibilities. ( Read https://en.wikipedia.org/wiki/Poisson_distribution ).The expected number of sound sources is modeled by the network while the GT is provided by point 1.
3) Audio is converted into spectrogram and both the audio and visual inputs are given to separate conv. networks to yield features.
4) Features are reshaped into (HXW) X C and then subjected to "soft" k-means clustering across HXW, where k=number of predicted sound sources. Here the number of visual "k" = number of audio k + 1. The addition of 1 is to capture the visual background which is not relevant to the sound source.
5) The audio and visual cluster centroids are aligned by training the cluster assignments with a contrastive loss which minimizes the distance between the audio and visual centroids of matching audio-image pairs and maximizing the distance between randomly sampled non-matching audio-image pairs.
6) For sound source localization we just find the closest visual cluster centroid corresponding to each audio cluster centroid. Cluster membership assignment is performed for each HxW which can be used as spatial masks to visualize the sound source. 
7) Curriculum procedure - train the network with single sound source samples and then fine tune with higher sound source samples

## Experiments
1) Model initialized with single sound source and then fine tuned on 3-sound source performs better than a randomly initialized model trained on only 3-sound source
2) Sound source localization model is trained on Audioset-Balanced and evaluated using Soundnet-Flickr dataset

## Observations
1) The experiment section is very confusing. Even though the number of sound sources ranges from 1 to 4, they only mention that pretraining on 1 improves when fine-tuning on 3. In a lot of experiments, they directly report on number of sound source=2 without mentioning whether the curriculum training was used or not.
2) Take-away point is the idea of employing curriculum learning by quantifying the level of difficulty as the number of sound sources in the audio-visual scene
